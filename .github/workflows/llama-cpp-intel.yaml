name: llama-server-intel Compile & Build & Push 

on:
  #push:
  #  branches: main
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * 0'

env:
  REGISTRY: ghcr.io
  IMAGE: llama-cpp-intel

jobs:
  build-and-push:
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      packages: write

    strategy:
      matrix:
        march: [alderlake, skylake]
    steps:
      - name: Maximize build space
        uses: easimon/maximize-build-space@master
        with:
          root-reserve-mb: 512
          swap-size-mb: 1024
          
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Log in to the GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ github.repository_owner }}/${{ env.IMAGE }}
          
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./dockerfile
          file: ./dockerfile/llama-cpp-intel/Dockerfile
          push: true
          tags: |
            ${{ steps.meta.outputs.tags }}-${{ matrix.march }}
          build-args: |
            MARCH=${{ matrix.march }}
